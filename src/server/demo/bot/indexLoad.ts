// å¯¼å…¥å¿…è¦çš„LangChainç›¸å…³ä¾èµ–
import { OpenAIEmbeddings } from "@langchain/openai";
import { FaissStore } from "@langchain/community/vectorstores/faiss";
import { Document } from "@langchain/core/documents";
import { RunnableSequence } from "@langchain/core/runnables";
import { ChatPromptTemplate } from "@langchain/core/prompts";

// å¯¼å…¥ç¯å¢ƒå˜é‡é…ç½®å’Œè‡ªå®šä¹‰èŠå¤©æ¨¡å—
import 'dotenv/config';
import chat from "../../helper/chat";
import { StringOutputParser } from "@langchain/core/output_parsers";

/**
 * å°†æ–‡æ¡£æ•°ç»„è½¬æ¢ä¸ºå•ä¸ªå­—ç¬¦ä¸²
 * @param documents - Documentç±»å‹çš„æ•°ç»„
 * @returns åˆå¹¶åçš„å­—ç¬¦ä¸²ï¼Œæ¯ä¸ªæ–‡æ¡£å†…å®¹ç”¨æ¢è¡Œç¬¦åˆ†éš”
 */
const convertDocsToString = (documents: Document[]): string => {
    return documents.map((document) => document.pageContent).join("\n")
}

async function main() {
    // åˆå§‹åŒ–OpenAI embeddingsé…ç½®
    // ç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
    const embeddings = new OpenAIEmbeddings({
        openAIApiKey: process.env.OPENAI_API_KEY,
        modelName: "text-embedding-ada-002",
        configuration: {
            baseURL: process.env.OPEN_API_BASE_URL,
        },
    })

    // æŒ‡å®šå‘é‡æ•°æ®åº“å­˜å‚¨ç›®å½•
    const directory = "./src/server/demo/bot/db/qiu";
    // ä»æŒ‡å®šç›®å½•åŠ è½½å·²å­˜åœ¨çš„FAISSå‘é‡å­˜å‚¨
    const vectorStoreLoad = await FaissStore.load(directory, embeddings);

    // åˆ›å»ºæ£€ç´¢å™¨ï¼Œè®¾ç½®è¿”å›2ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
    const retriever = vectorStoreLoad.asRetriever(2);

    // åˆ›å»ºä¸Šä¸‹æ–‡æ£€ç´¢é“¾
    // è¿™ä¸ªé“¾å°†ï¼š1.æå–é—®é¢˜ -> 2.æ£€ç´¢ç›¸å…³æ–‡æ¡£ -> 3.è½¬æ¢æ–‡æ¡£ä¸ºå­—ç¬¦ä¸²
    const contextRetriverChain = RunnableSequence.from([
        (input) => input.question,
        retriever,
        convertDocsToString
    ])

    // å®šä¹‰æç¤ºæ¨¡æ¿
    // è®¾ç½®AIè§’è‰²ä¸ºã€ŠçƒçŠ¶é—ªç”µã€‹åŸè‘—å…šï¼Œç”¨äºå›ç­”ç›¸å…³é—®é¢˜
    const TEMPLATE = `
    ä½ æ˜¯ä¸€ä¸ªç†Ÿè¯»åˆ˜æ…ˆæ¬£çš„ã€ŠçƒçŠ¶é—ªç”µã€‹çš„ç»ˆæåŸè‘—å…šï¼Œç²¾é€šæ ¹æ®ä½œå“åŸæ–‡è¯¦ç»†è§£é‡Šå’Œå›ç­”é—®é¢˜ï¼Œä½ åœ¨å›ç­”æ—¶ä¼šå¼•ç”¨ä½œå“åŸæ–‡ã€‚
    å¹¶ä¸”å›ç­”æ—¶ä»…æ ¹æ®åŸæ–‡ï¼Œå°½å¯èƒ½å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœåŸæ–‡ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œä½ å¯ä»¥å›ç­”"åŸæ–‡ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹"ï¼Œ
    
    ä»¥ä¸‹æ˜¯åŸæ–‡ä¸­è·Ÿç”¨æˆ·å›ç­”ç›¸å…³çš„å†…å®¹ï¼š
    {context}
    
    ç°åœ¨ï¼Œä½ éœ€è¦åŸºäºåŸæ–‡ï¼Œå›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
    {question}`;

    // åˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿
    const prompt = ChatPromptTemplate.fromTemplate(
        TEMPLATE
    );

    // åˆ›å»ºRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰é“¾
    // è¿™ä¸ªé“¾å°†ï¼š1.è·å–ä¸Šä¸‹æ–‡å’Œé—®é¢˜ -> 2.å¡«å……æç¤ºæ¨¡æ¿ -> 3.é€šè¿‡chatæ¨¡å‹ç”Ÿæˆå›ç­” -> 4.è§£æè¾“å‡ºä¸ºå­—ç¬¦ä¸²
    const ragChain = RunnableSequence.from([
        {
            context: contextRetriverChain,
            question: (input) => input.question,
        },
        prompt,
        chat,
        new StringOutputParser()
    ])

    // ç¤ºä¾‹ï¼šæŸ¥è¯¢ç›´å‡æœºç›¸å…³åœºæ™¯
    const answer1 = await ragChain.invoke({
        question: "è¯¦ç»†æè¿°åŸæ–‡ä¸­æœ‰ä»€ä¹ˆè·Ÿç›´å‡æœºç›¸å…³çš„åœºæ™¯"
      });
    console.log("ğŸš€ ~ main ~ answer1:", answer1)
}

// æ‰§è¡Œä¸»å‡½æ•°å¹¶æ•è·å¯èƒ½çš„é”™è¯¯
main().catch(console.error);